\documentclass[12pt,a4paper,ngerman]{scrartcl}

% Dateikodierung ist latin1%
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{listings}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{verbatim} 

% Color definitions
\definecolor{crucial}{RGB}{0,125,0} % This color marks the portions of code that are crucial (see below)

% Crucial marks keywords or statements that are crucial for passing the exam ;-)
\newcommand{\crucial}[1]{\textbf{\textcolor{crucial}{#1}}}

% Question Command
\newcommand{\question}[1]{\noindent{\textbf{{#1}}} \\*[0pt]}

% Answer environment
\newenvironment	{answer}
				{\noindent \ignorespaces \begin{addmargin}[1.5em]{0em}} % before
				{\end{addmargin} \noindent \ignorespacesafterend \\*} % after

\title{Technische Informatik 2 \\ Fragenkatalog \\ WISE 2012/2013 \\[5pt] \Large{Universität Bremen}}
\date{\today}

\begin{document}

\maketitle

\question{1. Welche zwei Hauptaufgaben hat ein Betriebssytem?}

\begin{answer}
	\begin{itemize}
	\item \crucial{Abstraktion von Geräteeigenschaften}
		\begin{itemize}
			\item Geräteunabhängige Schnittstelle zu den Anwendungen (virtuelle Maschine)
			\item Geräteüberwachung und -steuerung
		\end{itemize}
	
	\item \crucial{Unterstützung des Mehrbenutzerbetriebs}
		\begin{itemize}
			\item Betriebsmittelverwaltung
			\item Zuteilungsstrategien
			\item Schutz
		\end{itemize}
	\end{itemize}
\end{answer}

\question{2. Was ist ein Prozess?}
\begin{answer}
Ein \crucial{Programm in Ausführung}.
\end{answer}

\question{3. Wie ist ein UNIX-Dateisystem strukturiert? Wie können Dateien darin (eindeutig) aufgefunden
werden?}
\begin{answer}
Ein UNIX-Dateisystem ist \crucial{hierachisch organisiert}. Es \crucial{hat eine Wurzel} (root), Verzeichnisse
mit jeweils Unterverzeichnissen. In Vezeichnissen können Dateien abgelegt werden.
Vollstädnige Dateinamen sind Pfadnamen mit dem Dateinamen von der Wurzel aus.
\end{answer}

\question{4a. Was ist ein symbolischer Link (symbolic link)?}
\begin{answer}
Eine symbolische Verknüpfung ist eine \crucial{Verknüpfung} in einem Dateisystem, \crucial{die auf eine andere Datei oder ein anderes Verzeichnis verweist}. Es ist also lediglich eine Referenz auf die Zieldatei bzw. das Zielverzeichnis (d.h. ein weiterer Pfad zu einer Datei). Ein Löschen oder Verschieben der eigentlichen Datei führt üblicherweise dazu, dass die Referenz „ins Leere“ weist \crucial{(dangling link)}.
\end{answer}

\question{4b. Was ist ein Hardlink?}
\begin{answer}
Bei Hardlinks ist der Link ein \crucial{weiterer, regulärer Name der Datei}. Wird also die Datei unter ihrem ursprünglichen Namen gelöscht, ist sie unter ihrem zweiten Namen immer noch vorhanden. Intern wird dies durch Reference-Counting erreicht. Hardlinks \crucial{können nicht auf Verzeichnisse gelegt werden} (um Loops zu vermeiden).
\end{answer}

\question{5. Ist das UNIX-Dateisystem wirklich ein Baum? Begründung.}
\begin{answer}
Ein UNIX-Dateisystem entspricht eher einem \crucial{gerichteten Graphen} als einem Baum. Verzeichnisse und Dateien sind zwar hirarchisch organisiert, aber Möglichkeit von \crucial{Hardlinks}, d.h. das mehrfache Vorhandensein in der Dateistruktur einer physikalisch nur einfach vorhanden Datei stört das Bild eines Baumes. In einem Baum werden die Knoten benannt, unter UNIX werden Pfadnamen benutzt.
\end{answer}

\question{6. Welche Zugriffsrechte kann man auf eine UNIX-Datei haben? Welche Dateiattribute steuern dies, und wie?}
\begin{answer}
Die Zugriffsrechte sind Lesen, Schreiben und Ausführen.
Es können unterschiedliche Rechte für den Besitzer einer Datei, die Gruppe und den Rest
der Welt festgelegt werden.
\end{answer}

\question{7. Welche Vorteile bietet es, auf Terminals in UNIX wie auf Dateien zuzugreifen? Was versteht man unter Ein-/Ausgabeumlenkung?}
\begin{answer}
Da unter UNIX der Zugriff auf Geräte im allgemeinen (d.h. auch auf Terminals) als Zugriff
auf eine Datei geschieht, bietet dies den Vorteil der einheitlichen Schnittstelle. Der Benutzer
kann auf das Terminal zugreifen wie auf eine Datei auch und muss sich daher nicht mit
den konkreten Geräteeigenschaften auseinandersetzen.
Es gibt Standartein- und Standartausgaben von Prozessen. Will der Benutzer andere Einbzw.
Ausgabemöglichkeiten nutzen, kann er Ein- und Ausgaben umlenken. Beispielsweise
können die Fehlermeldungen in eine Datei umgelenkt werden.
\end{answer}

\question{8. Welche Aufgabe hat ein Kommando-Interpreter (z.B. in UNIX die Shell)?}
\begin{answer}
Ein Kommando-Interpreter stellt die Schnittstelle zum Benutzer zur Verfügung.
\end{answer}

\question{9. Nenne drei Beispiele für Informationen, die der Betriebsystemkern über einen Prozess wissen muss.}
\begin{answer}
Prozess ID, Parent-Prozess ID, Zustand des Prozesses.
\end{answer}

\question{10. Was ist eine Pipe?}
\begin{answer}
Eine Pipe ist die Umlenkung eines unidirektionalen sequentiellen Bitstroms von der Standartausgabe eines Prozesse auf die Standarteingabe eines Prozesses.
\end{answer}

\question{11. Wie macht man ein soeben editiertes Shell-File ausführbar?}
\begin{answer}
Setzen des Ausführbar-Bits (x).
\end{answer}

\question{12. In welche Bereiche (Segmente) ist der virtuelle Adressraum eines Programmes in Ausführung in UNIX unterteilt, und welche Eigenschaften kennzeichnen sie?}
\begin{answer}
Der virtuelle Adressraum ist in Text, Data und Stack unterteilt. Im Text-Teil befindet siche
der eigentliche Programmcode, im Data-Teil die Daten und auf dem Stack alle temparären
Daten (z.B. Variablen).
\end{answer}

\question{13. Wozu wird der Stack verwendet?}
\begin{answer}
Auf einem Stack werden die temporär anfallenden Daten eines Prozesses abgelegt. Z.B.
lokale Variablen.
\end{answer}

\question{14. Welchem Zweck dienen Bibliotheken (Libraries)?}
\begin{answer}
Bibliotheken stellen Funktionen zur Verfügung. Durch das Vorhandensein von Bibliotheken
muss ein Programmierer nicht von Grund auf alle Funktionen neu schreiben.
\end{answer}

\question{Welche Aufgabe erfüllt ein Linker?}
\begin{answer}
Ein Linker fügt die relativen Adressen beim compilieren in die Objektfiles ein.
\end{answer}

\question{16. Wozu wird beim Assemblieren eine Symboltabelle angelegt?}
\begin{answer}
Zum Auflösen von Verweisen.
\end{answer}

\question{17. Welchen Vorteil hat es, Bibliotheken mit Position Independent Code zu versehen?}
\begin{answer}
Laut Wikipedia: Position-independent Code (PIC, engl. für positionsunabhängiger Code) ist Maschinencode, der ausgeführt werden kann, unabhängig davon, an welcher absoluten Adresse im Hauptspeicher er sich befindet. PIC wird üblicherweise für dynamische Bibliotheken verwendet, damit diese für jedes Programm an eine Speicherposition geladen werden können, wo sie sich nicht mit anderen Objekten dieses Programms überlappen. 
\end{answer}

\question{18. Durch welche Qualitätsmerkmale soll ein Betriebssystem gekennzeichnet sein? Nenne Beispiele für konkurrierende Anforderungen.}
\begin{answer}
Effizienz, Kosten, Bedienbarkeit, Zuverlässigkeit, Verfügbarkeit, Sicherheit, Wartbarkeit.
Der Kostenpunkt kann mit jeder anderen Anforderung konkurrieren. Je besser ein Aspekt
werden soll, desto mehr Zeit und Entwicklungsarbeit, sprich Geld muss in diesen Aspekt
investiert werden. Am Beispiel Windows lässt sich wunderbar erkennen, wie Bedienbarkeit
und Zuverlässigkeit im Widerspruch zueinander stehen können. Die Sicherheit eines OS's
lässt sich oft auch nicht mit einer ausgereiften Bedienbarkeit vereinbaren, oder umgekehrt,
siehe Win vs. Linux.
\end{answer}

\question{19. Worin unterscheidet sich der Kernel-Mode vom User-Mode (in UNIX)? Warum wird diese
Unterscheidung getroffen?}
\begin{answer}
Kernel und Useradressraum sind aus Sicherheitsgründen getrennt. Im User-Mode kann
nicht auf die Hardware zugegriffen werden. Das hat auch seinen Sinn, da diese Zugriffe
kontrolliert erfolgen sollen, damit das System sicher und zuverlässig bleibt. Ein Greuel für
jeden Admin, wenn jeder Hans und Franz in seiner Konfig rumfuhrwerken dürften.
\end{answer}

\question{20. Was passiert etwa bei einem System-Aufruf?}
\begin{answer}
Es erfolgt ein Trap, darauf wird der Zustand des Systems gesichert, dann erfolgt der Sprung
in den Kernel-Mode, in dem der eigentliche Hardware-Zugriff erfolgt. Daraufhin gibt es
eine Rückmeldung und einen Rücksprung zum Prozess, wo dann auch der Kontext wieder
hergestellt wird.
\end{answer}

\question{21. Was ist ein Interrupt? Nenne Beispiele für mögliche Interrupt-Quellen. Warum werden sie
unterschiedlich priorisiert? Wie wird ein Interrupt in etwa behandelt?}
\begin{answer}
Ein Interrupt ist eine externe Unterbrechung eines Prozesses. Eine Quelle kann z. Bsp. die
Hardware sein. Hardwareinterrupts haben generell eine höhere Priorität als Softwareinterrupts.
Beim Clock-Tic ist die Quelle eben die Hardware, und der Prozess hat eine sehr hohe
Priorität, da ansonsten die System-Uhr nicht mehr genau laufen würde, was sich fatal auf
andere Programme auswirken kann, die sich nach dieser Uhr zu richten haben.
Beispiele für einen Softwareinterrupt wären SIGKILL oder SIGSTOP.
\end{answer}

\question{22. Was ist ein Trap? Nenne Beispiele für Traps. Inwiefern unterscheiden sich Traps von Interrupts?}
\begin{answer}
Ein Trap ist ein interne Unterbrechung eines Programms in Ausführung, die vom System
kommt. Beim Trap wird in den Kernel-Mode gewechselt, da es ja ein Systemaufruf ist.
Die Regelung erfolgt durch den Trap-Handler, der bei Bedarf dann auch Signale senden
kann. Division durch 0 wäre ein solches Beispiel. Es wird ein Trap ausgelöst, der durch den
Trap-Handler gejagt wird, welcher wiederum das Signal sigfpe lossendet (SignalFloating-
PointError). Die Folge ist, wie bei vielen anderen Signalen auch, dass der Prozess terminert
oder gekillt wird.
\end{answer}

\question{23. Was ist ein Signal? Nenne Beispiele für mögliche Signalquellen. Wie kann ein Prozess auf
ein Signal reagieren?}
\begin{answer}
Prozesse können Signale senden und empfangen. Stop, Kill, Terminate und Sleep sind
Signale. Der Traphandler ist eine Signalquelle. Ein Signal ist die Meldung eines besonderen
Zustandes von aussen. Eine Art vordefinierte Mechanismen des Systems, die adäquat
behandelt werden, aber auch umdefiniert werden können (ignore).
\end{answer}

\question{24. Beschreibe kurz einige Zustände, in denen sich ein (UNIX-)Prozess befinden kann.}
\begin{answer}
Laut Wikipedia:\\
Einfaches Modell:
Sleep, Run, Zombie, Ready.

Erweitertes Modell:
dead: Der Prozess wurde beendet, er belegt jedoch noch Speicherplatz.
ready: Der Prozess wartet auf Zuteilung der CPU (Zeitschlitz). Gibt es den Ready-Zustand, so befinden sich höchstens so viele Prozesse im Zustand running, wie CPUs vorhanden sind.
running: Entweder genau der Prozess, der gerade bearbeitet wird, oder alle Prozesse, die momentan Rechenarbeit verrichten können.
sleep: Der Prozess wurde auf eigenen Wunsch zurückgestellt. Er kann Signale entgegennehmen, wie z. B. Timer, oder Ergebnisse von Kindprozessen.
trace: Der Prozess wurde von außen angehalten, üblicherweise durch einen Debugger.
wait: Der Prozess wartet auf ein Ereignis, üblicherweise eine Benutzereingabe.
uninterruptible sleep: Der Prozess wartet auf ein Ereignis, üblicherweise Hardware. Tritt dieses Ereignis ein, ohne dass der anfragende Prozess es entgegennimmt, so kann das System instabil werden.
zombie: Der Prozess wurde beendet und aus dem Arbeitsspeicher gelöscht, aber noch nicht aus der Prozessliste entfernt.
\end{answer}

\question{25. Nenne einige Randbedingungen, auf die man beim Entwurf eines Schedulers achten sollte. Wie sollten rechen-intensive bzw. Ein-/Ausgabe-intensive Prozesse dabei behandelt werden?}
\begin{answer}
Ein Scheduler soll schlank (effizient) und fair sein, d. h. der Rechenaufwand der Prozessverwaltung
darf nicht so gross werden, dass die Effizienz darunter leidet, und jeder Prozess soll
gerechterweise auch drankommen. Auch die Zeitscheiben sollen eine angemessene Grösse
haben.
\end{answer}

\question{26. Wie könnte man mit Hilfe eines Round-Robin-Schedulers Prozess-Prioritäten simulieren?}
\begin{answer}
Man könnte die Anzahl der Durchläufe für die Prozesse mit einer hohen Priorität erhöhen,
so dass diese in einem Durchlauf mehrere Male dran kommen, oder man gibt den wichtigen
Prozessen grössere Zeitscheiben, um ihnen mehr CPU-Zeit zukommen zu lassen.
\end{answer}

\question{27. Warum bestehen die Sleep-Queue und die Run-Queue in UNIX nicht aus jeweils einer
einzigen Warteschlange? Wie sind sie stattdessen organisiert?}
\begin{answer}
Sleep-Queue und Run-Queue bestehen aus jeweils einem Array. Jede Priorität hat darin
eine eigene Liste, das Handling zwischen den Queues ist abhängig von der Priorität. Diese
Aufteilung besteht, da sonst immer alles durchsucht werden müsste.
\end{answer}

\question{28. Warum werden die Zustandsinformationen eines UNIX-Prozesses teilweise in der PROStruktur
und teilweise in der User-Struktur abgelegt? Nenne jeweils drei charakteristische
Beispiele für Angaben darin.}
\begin{answer}
Die in der Proc-Struktur abgelegten Zustandsinformationen sind für alle Prozesse verfügbar,
die in der User-Struktur abgelegten sind nur für den laufenden Prozess verfügbar.
Beispiele für Angaben in der Proc-Struktur:
Signale, die zur Verarbeitung anstehen
Prozesszustände
Scheduling
Beispiele für Angaben in der User-Struktur:
Zugriffsrechte
Aktuelles Verzeichnis
Geöffnete Dateien.
\end{answer}

\question{29. Skizziere kurz die Prozesserzeugung in UNIX.Welche Rolle spielen die Systemaufrufe fork()
und exec() dabei?}
\begin{answer}
Der Prozess Nummer Eins (INIT) wird "von Hand" beim Systemstart erzeugt.
Andere Prozesse werden bei Bedarf als Kindprozesse mit fork() (oft als Kind-Prozesse
der Shell) erzeugt. So entsteht eine Hierachie von Prozessen. Der Kindprozess erhält eine
neue Prozess-ID, ist aber zunächst eine Kopie des Vaters, d.h. der"gleiche" Adressraum
mit gleicher Aufteilung von Text, Data und Stack. Normalerweise soll das Kind ein anderes
Programm ausführen, dieses wird mit exec() gestartet, damit wird dann auch der
Adressraum ausgetauscht.
\end{answer}

\question{30. Wie erfährt ein UNIX-Prozess, ob ein Kindprozess terminiert ist? Wozu gibt es in UNIX den Prozesszustand SZOMB ("Zombie")?}
\begin{answer}
Das Kind meldet bei der Termination das Signal SIGCHILD an den Vater, dieser behnadelt
durch den Aufruf wait() den Kindprozess und der Kindprozess terminiert
oder der Vater ignoriert das Signal. In diesem Fall wird das Kind zum Zombie. Der Zombie
wird dann entweder später vom Vater behandelt oder (je nach UNIX-Variante) durch das
Betriebssystem. Z.B. kann der INIT-Prozess die Proc-Struktur wieder freigeben.
\end{answer}

\question{31. Welche Vor- und Nachteile hat der First-Fit- bzw. der Best-Fit-Algorithmus zur Speicherverwaltung?}
\begin{answer}
Wie funktioniert der Buddy-Algorithmus in etwa?
First-Fit-Algorithmus:
Der erste Block, der gross genug ist, wird verwendet indem er in zwei Teile gespalten wird
(gross genug für die Anforderung und Rest).
Das führt zu einer Ansammlung von kleinen Blöcken am Anfang der Liste, es werden immer
mehr Blöcke und sie werden im Mittel immer kleiner. Das führt zu im Mittel längerer
Suche, kleine Anforderungen können schnell erfüllt werden.
Best-Fit-Algorithmus:
Die Liste wird immer ganz durchsucht, der Block mit dem kleinsten Verschnitt wird ausgew
ählt.
Es entstehen extrem viele kleine Blöcke. Die Suche dauert sehr lange da immer die ganze
Liste durchsucht wird. Es sind lange auch grosse Blöcke verfügbar.
Buddy-Algorithmus:
Blöcke sind immer 2k gross. Bei der Freigabe eines Blockes wird er, wann immer sein
Nachbar (Buddy) frei ist, mit dem Nachbarn verschmolzen.
Das vereinfacht das splitten und zusammenfügen der Blöcke. Allerding entsteht freier Speicher
innerhalb der Blöcke.
Optimierung: mehrere Listen mit jeweils gleich grossen Blöcken, das verringert die Suchdauer.
\end{answer}

\question{32. Wozu bieten Systeme eine Speicherhierachie an? Welche Beobachtung über den Speicherzugriff realer Programme liegt dem zugrunde? Welche verschiedenen Arten von Speicher
werden typischerweise bereitgestellt?}
\begin{answer}
Die Systeme bieten eine Speicherhierachie an da die Geschwindigkeit sich konträr zu den
Kosten verhält.
Reale Programme greifen oft nur auf eine sehr kleine Bereich zu (Working Set).
Es werden meist Cache, Hauptspeicher und Massenspeicher bereitgestellt.
\end{answer}

\question{33. Warum ist es in der Regel nicht sinnvoll, den Adressraum eines Prozesses in einem Stück im Speicher abzulegen?}
\begin{answer}
Ein Prozess muss nicht zwangsläufig komplett im Speicher verfügbar sein (s.o.:Working
Set). Bei der Aufteilung in kleinere Einheiten ist auch die Nutzung kleinerer Freispeichereinheiten
möglich, heisst insgesamt eine erheblich bessere Nutzung des Haupspeichers.
\end{answer}

\question{34. Was versteht man unter Paging, was unter Segmentierung? Wo tritt interne Fragmentierung,
wo externe Fragmentierung auf? Was versteht man darunter?}
\begin{answer}
Segmentierung:
Speicher wird in verschieden grosse Stücke unterteilt, das ermöglicht die 
exible Zuteilung
kleiner Speicherbereiche und Shared Memory.
Es sind Adressumsetzungstabellen pro Prozess notwendig.
Segmente enthalten unterschiedlich viele Pages und sind maximal 210Bytegross:
Paging:

exible Zuteilung von gleich grossen Speichereinheiten. Der Hauptspeicher wird in Kacheln (PageFrames)
fester Grösse unterteilt, die Prozessadressräume wiederum liegen in Seiten (Pages) von
gleicher Grösse. Auch dieses Verfahren ermöglicht Shared Memory, impliziert aber interne Fragmentierung.
externe Fragmentierung: wenn durch die angewendete Logik Speicher in unterschiedlich grosse
Stücke eingeteilt wird und ganze Stücke freibleiben.
interne Fragmentierung: wenn innerhalb von gleich grossen Stücken der Speicher nicht restlos
ausgenutzt wird und so Speicher ungenutzt bleibt.
\end{answer}

\question{35. Aus welchen Teilen besteht eine virtuelle Adresse zumeist? Wie ermittelt sich daraus die entsprechende
Hauptspeicheradresse, d.h. wie läuft die Adressverwaltung in etwa ab?}
\begin{answer}
Eine virtuelle Adresse besteht zumeist aus zwei Teilen: jPAGEjADDRj. Der erste Teil wird bei
Gebrauch in der Page-Tabelle "nachgeschaut" und entsprechend ersetzt: jADDRjADDRj.
Dieser Vorgang wird üblichwerweise durch Hardwareunterstützung realisiert: die Memory Managment
Unit (MMU).
\end{answer}

\question{36. Wie können mehrere Prozesse mit Hilfe virtueller Adressierung auf dieselben Programmstücke (oder auch Datenbereiche) zugreifen?}
\begin{answer}
Shared Memory:
In den jeweiligen (unterschiedlichen) Page-Tabellen sind dieselben Seiten eingetragen. (Doppelter
bzw. dreifacher Eintrag ein und desselben Inhalts in die 'Inhaltsverzeichnisse').
\end{answer}

\question{37. Wie arbeiten die folgenden Algorithmen zur Verdrängung von Seiten aus dem Hauptspeicher in
etwa?}
\begin{answer}
LRU (Least-Recently-Used)
LRU entfernt die Seite im Hauptspeicher, auf die am längsten nicht mehr zugriffen
wurde. Das Lokalitätsprinzip wird in der Regel gut erfasst. LRU besitzt eine gute
Aproximation an den optimalen Algorithmus,
aber das erfassen aller Zugriffszeiten auf die Seiten ist notwendig, d.h. bei jedem
Zugriff müssen weitere Speicherzugriffe erfolgen. LRU ist zu aufwendig ohne Spezialhardware.

FIFO (First-in-First-Out)
FIFO entfernt die älteste Seite und ist einfach zu realisieren: als verkettete Liste der
Page Frames nach Belegungsalter.
Aber: bestimmt das Working Set in der Regel nicht gut.

Second-Chance-FIFO
Funktioniert (im Prinzip) wie FIFO: als verkettete Liste nach Belegungsalter. Wenn
eine Seite (nach FIFO) zum Löschen an der Reihe ist wird überprüft ob sie seit
ihrer letzten überprüfung referenziert wurde. Wenn ja: sie wird wieder (als jüngste
Seite) in die Liste eingehängt. Wenn nein: löschen der Seite.
In diesem Algorithmus wird unterschiedliche Benutzungshäufigkeit einkalkulliert,
aber er ist sehr aufwendig, da auch eine FIFO-Liste geführt werden muss (s.o.)

NRU (Not-Recently-Used)
NRU trifft eine zufällige Auswahl aus den kürzlich nicht referenzierten Seiten (z.B.
mit zyklischer Suche nach Page Frame-Nummern). Der gewählte Modus des zurücksetzens
des Referenzbits entscheidet über die Güte".
Mögliche Optimierung:
Unterscheidung zwischen Nur-Lese-Zugriffen und Schreib-Zugriffen, wird in Dirty-
Bit (D) = Modifikationsbit (M) angegeben.
Da bei kürzlich beschriebenen Seiten der veränderte Seiteninhalt erst gerettet werden
muss, sollte wegen des Aufwandes eher eine Seite mit Nur-Lese-Zugriffen zum
überschreiben gwählt werden.

Bei Lastspitzen summiert sich die Verdrängung von beschriebenen Seiten, daher
wird NRU oft nicht verwendet.
Aging
Beim Aging altern die Seiten duch shiften eines Schieberegisters das für jede Seite
angelegt wird. Das führt zu einer guten Annäherung an LRU, aber auch zu unbertretbar
hohem Aufwand. Bei Vereinfachung des Algorithmus (z.B. von Schieberegister
mit 8 Bit auf 2 Bit) gehen die LRU-ähnlichen Vorteile verloren und Aging wird
zu komplexen Variante von Second-Chance-FIFO.
\end{answer}

\question{38. In welche dieser Kategorien kann man den Clock-Hand-Algorithmus einordnen?}
\begin{answer}
LRU (ohne Dirty-Bit)
\end{answer}

\question{39. Warum ist ein optimaler Algorithmus nicht realisierbar?}
\begin{answer}
Ein optimaler Algorithmus ist für ein 'normales' Betriebssystem nicht realisierbar, da die Prozesse
durch unterschiedliche Working Sets eine unterschiedlich grosse Anzahl von Seiten unterschiedlich
lange benötigen.
Im Gegensatz dazu ist bei einem Betriebssystem mit wenigen, speziellen Aufgaben (Embeded
Systems) ein optimaler bzw. annähernd optimaler Algorithmus möglich.
\end{answer}

\question{40. Was passiert, wenn die Umlaufzeit des Zeigers beim Clock-Hand-Algorithmus zu gross bzw. zu
klein gewählt wird? Wie kann ein zweiter Zeiger den Algorithmus verbessern?}
\begin{answer}
Wenn die Umlaufzeit zu gross gwählt wird ist irgendwann kein freier Speicher mehr verfügbar (die
Freispeichereserve leer).
Wird die Umlaufzeit zu klein gewählt, werden die Seiten vor ihrer nächsten Benutzung aus dem
Speicher entfernt und müssen dann erneut geladen werden, die Freispeicherreserve ist grösser als
sinnvoll.
Ein zweiter Zeiger verbessert den Clocl k-Hand-Algorithmus insbesondere bei grossen Mengen von
Speicher. Z.B. kann der erste Zeiger das Referenzbit gegebenenfalls zurücksetzen, der Zweite die
Seiten entfernen falls sie in der Zwischenzeit nicht erneut referenziert wurden.
\end{answer}

\question{41. Was ist Swapping?Warum wenden auch Paging-Systeme häufig dieses Verfahren an? Unter welcher
Bedingung?}
\begin{answer}
Swapping wird angewandt wenn die Working Sets der aktiven Prozesse nicht vollständig in den
Speicher passen.
Dadurch entsteht eine hohe Page Frame-Rate, das so genannte Seiten-Flattern. Da das Lesen
von der Festplatte recht lange dauert, sinkt die Geschwindigkeit, in der die Instruktionen abgearbeitet
werden können, rapide.
Durch Swapping werden nicht nur Teile von Prozessen (Paging), sondern ganze Prozesse auf die
Platte ausgelagert. Längere Zeit inaktive Prozesse werden aus dem Hauptspeicher entfernt, um
dort Platz verfügbar zu machen, dadurch wird natürlich ein Austausch der Prozesse im Hauptspeicher
nach gewisser Zeit erforderlich.
\end{answer}

\question{42. Wie kann man die Vorteile von Paging und Segmentierung kombinieren?}
\begin{answer}
Bei einem einzigen Adressraum kann dieser beim Paging nicht logisch aufgeteilt werden. Der gesamte
Adressraum wird in gleich grosse Kacheln eingeteilt.
Deswegen wird heute der Speicher häufig in mehrere Segmente unterteilt, die jeweils eigene Pagetabellen
enthalten. Die Grösse der Segmente ist nicht statisch, sondern kann jede Gösse mit n
multipliziert mit Page Frame Grösse umfassen.
Dadurch entstehen dreiteilige Adressen:
Region mit eigener Pagetabelle, Page in der Region, Adressein Page.
Regionen folgen dabei der logischen Grösse des Adressraumes (Text, Data, Stack), Pages sind in
feste Grössen unterteilt.
\end{answer}

\question{43. Wozu wird bei der Speicherverwaltung häufig ein Assoziativspeicher eingesetzt?}
\begin{answer}
Assoziativspeicher wird im allgemeinen als Spezialhardware innerhalb der MMU (Memory Managment
Unit) realisiert. D.h. Assoziativspeicher == Hardware-Cache.
Er wird häufig zur Adressumsetzung genutzt. Für die gesamte Pagetabelle wäre dies sehr teuer,

deswegen wird beim Prozesswechsel neu geladen, es sind (getreu dem Lokalitätsprinzip) immer nur
einige Seiten in Gebrauch. Daher enthält der Cache jeweils nur diese Seiten. Ablauf: Adresszugriff,
Page Table Entry im Cache? Wenn ja: Adressumsetzung, wenn nein: Nachladen aus der Pagetabelle.
Es ist der parallele Zugriff auf alle im Cache befindlichen Einträge möglich. Die gesamte Pagetabelle
im Hauptspeicher vorzuhalten, wäre zu langsam, da zusätzlicher Speicherzugriff nötig
wäre.
\end{answer}

\question{44. Beschreibe kurz die Zugriffsoperationen open(), close(), lseek(), read() und write() auf ein UNIXFilesystem.}
\begin{answer}
Welche Rolle spielt der File Descriptor dabei?
open()
Öffnet eine Datei für die weitere Arbeit. open() werden die Parameter path (Pfadname der Datei),

ags (erlaubte Folgeoperationen wie lesen, schreiben,...) und mode (Zugriffsrechte bei einer NEU
angelegten Datei) übergeben. Der File Descriptor wird zurückgegeben.
close()
Dieser Systemaufruf gibt eine Datei wieder frei.
create()
Es wird mit den Parametern path und mode eine neue Datei erzeugt. Der File Descriptor wird
zurückgegeben.
lseek()
wird mit den Parametern File Descriptor, offset und whence aufgerufen. Die aktuelle Position im
File Descriptor wird um offset Bytes gemäss whence verschoben (d.h. 0 = vom Anfang, 1 = vom
Ende, 2 = von der aktuellen Position aus).
Zusammengefasst: lseek setzt den Zeiger, der innerhalb einer Datei die Position anzeigt.
read()
mit den Parametern File Descriptor (fd), buf und len liest von len Bytes ab der aktuellen Position
des fd in den Puffer buf, dabei wird die aktuelle Position um die gelesenen Bytes weitergeschoben.
read() liefert die Anzahl der tatsächlich gelesen Bytes.
write()
mit den Parametern fd, buf und len funktioniert analog zu read() und liefert die Anzahl der geschriebenen
Bztes zurück.
\end{answer}

\question{45. Wie sieht die Struktur des UNIX-V7-Dateisystems auf der Platte in etwa aus? Warum erfolgt die Verwaltung der Freispeicherliste über Indirekt-Blöcke?}
\begin{answer}
Das Dateisystem V7:
- Der Dateiinhalt ist Block-orientiert mit speziellem Block-Index organisiert.
- Der Boot-Block ist Block 0 des Root-Dateisystems und wird beim booten geladen.
- Der Superblock enthält die Verwaltungsinformationen des Dateisystems: Grösse, Verwaltung der
freien Inodes, Verwaltung der freien Blöcke (mit verketteter Liste von Blöcken mit freien Blocknummern)
- Inodes dienen zur Ablage der Verwaltungsinformationen der Dateien. Jede Datei hat einen Inode
mit:
+ eindeutigem Bezeichner (heisst: Inodenummer, diese gibt die Position an)
+ Besitzer (nid), Gruppe (gid)
+ Zeitpunkt der letzten änderung, des letzten Zugriffs, ...
+ Anzahl der Hard Links (mehrere Namen für eine Datei verweisen auf denselben Inode)
+ Anzahl von Bytes
+ Dateityp
+ Verweise auf Datenblöcke
+ Zugriffsrechte
Kleine Dateien bis zu zehn Blöcken werden direkt im Inode-Block gespeichert.
- In Indirekten Blöcken sind alle Dateien grösser als zehn Blöcke organisiert. Jeder Indirekt Block
hat auch ist auch in den Inodes mit einem Eintrag vorhanden. Mit Indirekten Blöcken sind grosse
Dateien realisierbar, mit maximal vier Zugriffen für einen Dateiblock.
Die Aufteilung in verschiedene Blöcke dient insbesondere der Sicherheit, so wird z.B. der Superblock,
ohne den der Rest des Systems nicht mehr zugreifbar ist, mehrfach an verschiedenen Stellen
der Platte gespeichert. So können die wichtigsten Informationen bei der Zerstörung des Original-
Superblockes wiederhergestellt werden. Des weiteren können durch Verschleiss kappute Blöcke als
nicht benutzbar deklariert werden. Das Gegenbeispiel zur Organisation in Blöcken ist die Organisation
als verkettete Liste, heisst bei eine Störung der verkettene Liste durch einen kapputen

Block (z.B.) sind alle folgenden Listeneinträge nicht mehr erreichbar.
\end{answer}

\question{46. Welche Aufgaben enthält ein Inode? Welche Angaben enthält eine Verzeichnis-Datei (Directory)?}
\begin{answer}
Aufgaben von Inodes: siehe oben. Eine Verzeichnis-Datei (Directory) ist eine Datei und hat entsprechend
einen eigenen Inode und Datenblöcke. Verzeichnisse sind eine Folge von Einträgen, die
jeweils den Dateinamen (auch Dateinamen von Unterverzeichnissen) und die jeweilige Inodenummer
enthalten.
\end{answer}

\question{47. Welche Aufgaben hat der Buffer Cache in UNIX?}
\begin{answer}
Der UNIX-Buffer Cache ist ein Zwischenspeicher (Puffer) für gelesene oder geschriebene Plattenbl
öcke im Kernadressraum. Er puffert Ein- und Ausgabe vom User-Adressraum entkoppelt. Der
Buffer Cache ermöglicht Mehrfachzugriff ohne weitere Plattenzugriffe.
Die Daten werden von Platte zu Cache in Blöcken transportiert, von Cache zu CPU in Bytes.
\end{answer}

\question{48. Was geschieht durch einen mount()-Systemaufruf in etwa?}
\begin{answer}
Unter UNIX kann eine physikalische Harddisk in mehrere logische Partitionen eingeteilt sein. Jede
dieser Patitionen enthält ihr eigenes Dateisystem, ein UNIX-System kann also aus mehreren solcher
Dateisysteme zusammengesetzt sein. Mit dem Befehl mount wird ein weiteres Dateisystem
in einen solchen Dateibaum (Wurzel: Root) eingehängt, d.h. verfügbar gemacht. Beim mounten
werden logische Geräte (z.B. CDROM, Partition, ...) und der Mount Point übergeben.
\end{answer}

\question{49. Welche Vorteile bietet es, Dateien mit dem UNIX-Systemaufruf mmap() in den virtuellen Adressraum eines Prozesses abzubilden?}
\begin{answer}
I/O Performance steigt durch:

\begin{itemize}
\item Lazy Loading 
\item Keine Systemaufrufe notwendig
\item Das Betriebssytem arbeitet meistens direkt auf dem Buffercache, so dass keine Kopie im Userspace Addressraum angelegt werden muss.
\end{itemize}

\end{answer}

\question{50. Wie ist eine Platte intern organisiert? Wie wirkt sich dies auf den Informationszugriff aus? Wie geht das UNIX Fast File System damit um?}
\begin{answer}
Eine physikalische Festplatte besteht aus sechs bis zehn internen Platten (Scheiben). Auf jede
dieser internen Platten greift jeweils von oben und von unten ein Lese-Schreibkopf zu. Jede
Oberfläche ist in Spuren unterteilt, jede Spur in Sektoren. übereinanderliegende Spuren auf den
verschiedenen Oberflächen bilden Zylinder. Da für jede Armbewegung relativ viel Zeit benötigt
wird, sollten Armbewegungen möglichst vermieden werden. D.h. zusammengehörende Daten sollten
in hintereinanderliegenden Sektoren in derselben Spur untergebracht werden, damit das Lesen
und Schreiben in Vorgang ohne weitere Armbewegung vorgenommen werden kann. Ist die Datenmenge
grösser, sollten die Spuren innerhalb des gleichen Zylinders verwendet werden.

% FIXME
UNIX Fast File System:
Das System arbeitet auf vier bzw. acht Byte grossen Datenblöcken. Die Platte ist in Zylindergruppen unterteilt. Jede Zylindergruppe hat einen eigenen Inode- und Datenbereich, Dateien und ihr Inode werden möglichst in derselben Zylindergruppe gespeichert. Ein Verzeichnis und die darin enthaltenen Dateien werden wiederum in derselben Zylindergruppe gespeichert, dies gilt aber nicht für im Verzeichnis befindliche Unterverzeichnisse.
\end{answer}

\question{51. Welche Vorteile bietet eine vereinheitlichte Betriebssystemschnittstelle für den  Zugriff auf Geräte? Wie sieht die in UNIX in etwa aus?}
\begin{answer}
In UNIX sind Geräte als Datein dargestellt. Dies bietet für Anwender und Programmierer den
Vorteil, dass sie einheitlich zu behandeln sind.

\paragraph*{Laut Wikipedia:}
Everything is a file (engl. ‚Alles ist eine Datei‘) beschreibt eine der definierenden Eigenschaften von Unix und seinen Abkömmlingen, dass eine große Bandbreite an Ein-/Ausgabe-Ressourcen wie Dokumente, Verzeichnisse, Festplatten, Modems, Tastaturen, Drucker und sogar Interprozess- und Netzwerkverbindungen als einfache Byteströme via Dateisystem verfügbar sind.
\end{answer}

\question{52. Was ist ein Gerätetreiber, was ein Geräte-Controller? Welche Aufgaben haben sie?}
\begin{answer}
Gerätetreiber:
- ist Code innerhalb des Betriebssystems zur Geräteverwaltung
- es existiert jeweils ein Treiber pro Gerätetyp, die Typen werden durch die Major Number unterschieden
- als Parameter wird die Minor Number benötigt, um die konkrete Hardware zu identifizieren /
anzusprechen. Controller:
- ist Hardware, die sich zwischen CPU und Gerät befindet
- enthält unter anderem einen Puffer für die Zwischenlagerung von Aufträgen an das Gerät
- zur Aktivierung des Controllers werden die Aufträge in Controllereigenen Registern abgelegt
Ein Treiber ist also zum Kernel gehörende Software, ein Controller ist die zu einem Gerät gehörende,
vom Treiber gesteuerte, Hardware.
\end{answer}

\question{53. Warum erfolgt der Zugriff auf Geräte häufig über Warteschlangen? Wozu besitzten diese in der Regel eine High Water Mark bzw. eine Low Water Mark?}
\begin{answer}
Der Zugriff über Warteschlangen erfolgt um eine Vermischung von Aufträgen und das Verlorengehen von Aufträgen zu verhindern. Desweiteren um die komplette Abarbeitung eines Auftrages zu gewährleisten und die Reihenfolge der Auftragsabarbeitung zu organisieren.
Die Warteschlangen besitzen in der Regel eine High Water Mark, um anzuzeigen, dass die Warteschlange voll ist, d.h. um zu verhindern das entweder ein Auftrag in der Schlange überschrieben wird oder ein Auftrag verlorengeht. Die Low Water Mark zeigt dagegen an, dass weitere Aufträge "nachgefüllt" werden können.
\end{answer}

\question{54. Worin unterscheidet sich Direct Memorz Access (DMA) von Programmed I/O?}
\begin{answer}
Beim Programmed
I/O ist der Ablauf wie unter 7.2 beschrieben, da der Treiber ein Teil des Betriebssystems ist, bleibt letztendlich die Kontrolle des Vorgangs bei der CPU. Beim Direct Memory Access (DMA) liegt nach dem Anstoss eines Auftrages der Zugriff auf den
Hauptspeicher und die daraus vorzunehmenden Kopiervorgänge in der "Verantwortung" des Controllers.
Der Controller greift nach der Abarbeitung eines Auftrages ohne Einbeziehung der CPU
auf den Hauptspeicher zu. Zu diesem Zweck muss der Auftrag selbst die entsprechenden Speicherbereiche
angeben.
\end{answer}

\question{55. Warum werden Terminal-Treiber in UNIX parametrisiert? Nenne typische Parameter.}
\begin{answer}
Geräte können unter Umständen in verschiedenen Modi laufen. Um den gewünschten Modus zu
erzeugen, benötigt ein Treiber die Angabe desselben mit Hilfe eines Parameters => Parametrisierung.
Ein typischer Parameter wäre bei einem Monitor z.B. die Farbtiefe.
Bei Terminals werden grundsätzlich zwei Modi unterschieden: der Raw-Modus (Canonical Mode),
in ihm werden einem Terminal Tasteneingaben unverändert und zeichenweise an des Pozess
weitergereicht. Im Cooked-Modus (Noncanonical Mode)wird die Tasteneingabe zeilenweise an den
Prozess weitergegeben. In diesem Modus ist es möglich, Tastenkombinationen abzufangen (also
erst einmal nicht an den Prozess weiterzugeben) und ihnen besondere Funktionen zuzuweisen.
Z.B. Zeileneditierfunktionen wie: BS, DEL, Strg-w,... zu verarbeiten und dann in der neuen Form
an den Prozess weiterzugeben. Weitere Beispiele hierfür sind die Flusskontrolle mit Strg-s (stoppt
Ausgabe) oder Strg-q (weiter) oder Signale wie Strg-c (stoppt den Prozess mit SIGINT).
\end{answer}

\question{56. Skizziere kurz einige Probleme des nebenläufigen Zugriffs auf Betriebsmittel.}
\begin{answer}
Zwei Prozesse dürfen nicht gleichzeitig auf ein Betriebsmittel zugreifen (kritischer Abschnitt). Es
kann hier zu Verklemmungen, dem After-you-after-you Problem und dem Verhungern kommen.
Bei nebenläufigeZugriff kann es zu inkonsisten Daten kommen, wenn der gegenseitige Ausschluss
nicht gewährleistet ist.
\end{answer}

\question{57. Grenze die Begriffe Nebenläufigkeit, Quasi-Parallelität und Parallelität voneinander ab. Was verstehen wir unter Nichtdeterminismus?}
\begin{answer}
Nebenläufigkeit ist das Abarbeiten von mehreren Prozessen mit einer CPU. Paralellität ist das
Abarbeiten von Prozessen mit einer Mehrprozessormaschine.
\end{answer}

\question{58. Welche Nebenläufigkeitseigenschaften bzw. -probleme werden durch die drei folgenden "klassischen" Szenarien ausgedrückt?}
\begin{answer}
a) Erzeuger/Verbraucher (Producer/Consumer)
b) Leser/Schreiber (Reader/Writer)
c) Speisende Philosophen (Dining Philosophers)?
\end{answer}

\question{59. Was ist ein Thread ("Faden")? Skizziere ein sinnvolles Anwendungsbeispiel für die Verwendung mehrerer Threads innerhalb eines Prozesses.}
\begin{answer}
TODO 
\end{answer}

\question{60. Grenze den Thread-Begriff gegen den UNIX-Prozess ab (Adressraum, Zustandsinformationen,
etc.). Was haben Light-Weight-Prozesse (LWPs) damit zu tun?}
\begin{answer}
Ein Prozess hat einen eigenen Adressraum und ist somit stark abgeschottet gegenüber anderen
Prozessen. Prozesse können aus anderen Prozessen erzeugt werden und arbeiten trotzdem weiter,
wenn der Vater-Prozess terminiert ist. Prozesse sind eigenständig.
Threads sind mehrere Kontrollfäden in einer Hülle, nämlich dem Prozess, aus dem sie aufgerufen
wurden. Threads haben zwar einen eigenen Ausführungszustand (PC,Stack) dafür aber eine
gemeinsame Umgebung (Adressraum, offenen Dateien, gemeinsame Datenstrukturen). Hier kann
es zu kritischen Abschnitten kommen. Eine Synchronisation ist erforderlich. Einem Thread muss
Arbeit (eine Prozedur) zugewiesen werden. Ein Thread ist beendet, wenn die Umgebung, der Prozess
terminiert. Ein Thread ist also von der Umgebung abhängig.
Ein Problem ist, dass der Betriebssystemkern nichts vom Erzeugen der Threads erfährt, es ist also
keine "echte Nebenläufigkeit" gegeben.
Light-Weight-Prozessen dagegen sind dem Bestriebsystemkern bekannt. Das stellt die Grundlage
für das Scheduling dar.
\end{answer}

\question{61. Die Routinen pthread create(), pthread join(), pthread exit() realisieren die Erzeugung und Termination von Threads in der UNIX-Multithreading-Umgebung. Vergleiche ihre Funktionalität mit den Systemaufrufen zur Erzeugung und Termination von Prozessen (wait(), fork() und exit()). Warum arbeitet pthread create() deutlich anders als fork()?}
\begin{answer}
thr create() / fork()
thr create():
Thread wird Prozedur zugewiesen, hat eigen Ausführungszustand (PC,Stack)
fork():
erstellt eine Kopie des Adressraumes. Kind kann weiterarbeiten nachdem der Vater bereits terminierte.
thr join() / wait()
thr join():
sammelt Thread ein wenn er beendet ist. Bei Prozessende werden eventuell nichtabgeschlossene
Threads beendet.
wait():
wartet auf die Terminierung eines Prozesses. Welcher Prozess kann über die Prozess-ID abgefragt
werden.
thr exit() / exit()
thr exit():
zum vorzeitigen Beenden von Threads
exit():
zum vorzeitigen Beenden von Prozessen
thr create erzeugt in einer gemeinsamen Umgebung einen eigenen Ausführungszustand. Dazu muss
beim Erzeugen unter anderem auch eine Stack-Info erstellt werden. Mit Threads ist es möglich,
von einem Programmfaden in mehrere überzugehen. fork() ist dagegen so ausgelegt, dass ein
eigenständiger Prozess erzeugt wird. Dieser wird auch vom Scheduler berücksichtigt, da er dem
Betriebsystemkern bekannt ist.
\end{answer}

\question{62. Was versteht man unter einseitiger bzw. mehrseitiger Synchronisation? Gib jeweils ein Anwendungsbeispiel an.}
\begin{answer}
TODO
\end{answer}

\question{63. Was ist ein kritischer Abschnitt? Wie kann man den gegenseitigen Ausschluss gewährleisten? Warum ist ein Unterbrechungsausschluss dabei nicht immer das geeignete Mittel?}
\begin{answer}
Ein kritischer Abschnitt ist ein Programmteil, in dem von mehreren Programmabäufen auf eine gemeinsame
Datenstruktur oder auf ein Betriebssystemmittel zugegriffen wird. Kritische Abschnitte
müssen daher geschützt werden. Sonst würde es eventuell zu falschen Ergebnissen kommen. jeder
kritische Abschnitt benötigt daher einen Schliessmechanismus, der durch eine "Schlossvariable"
realisiert wied. Bei Betreten eines kritischen Abschnitts wird dann diese Variable gesetzt (oft Boolean
TRUE). Andere Programmabläufe müssen nun den Status der Schlossvariablen nachfragen,
um zu erfahren, ob der kritische Abschnitt frei ist oder nicht.
Möglichkeiten, den gegenseitigen Ausschluss zu gewährleisten:
- eigene Absicht anmelden, dann überprüfen ob anderer auch will. Jeder Programmablauf benötigt
eine eigene Schlossvariable. Sobald einmal die Absicht einzutreten erklärt wurde, ist der kritische
10
Abschnitt gesperrt. Der gegenseitige Ausschluss ist somit gewährleistet.
Problem: Wenn zwei Programmabläufe nebenläufig die Absicht anmelden, können beide Abläufe
in einer Endlosschleife hängenbleiben, weil sie darauf warten, dass der andere den kritischen Abschnitt
freigibt.
- Unterbrechungen ausschalten. Andere Programmabläufe können nun nicht mehr einen anderen
unterbrechen, wenn sich dieser im kritischen Abschnitt befindet.
- andere Prozesse blockieren>: hier werden andere programmabläufe einfach blockiert, egal ob sie
nun auf kritische Abschnitte zugreifen können oder nicht.
- wenn trotdem andere prozesse während eines kritischen Abschnitts zugelassen werden sollen,
dann müssen wie oben mechanismen gefunden werden, um den kritischen Abschnitt zu schützen.
Gegenseitiger Ausschluss durch Unterbrechungsausschltung funktioniert nur bei Einprozessorsystemen.
Wenn ein Prozess sich in einem kritisdchen Abschnitt befindet, und nicht selbst wieder
herauskommt (z.B. Endlosschleife), wäre es nicht sinnvoll, hier die Unterbrechung auszuschalten.
\end{answer}

\question{64. Nach welchen Kriterien wird Korrektheit bzw. Güte von Locking-Algorithmen bewertet? Wie geht man dabei vor?}
\begin{answer}
Der Zugriff auf Schlossvariablen darf nicht selbst in einem kritischen Abschnitt liegen. Locking-Algorithmen sollten verklemmungsfrei arbeiten.
\end{answer}

\question{65. Warum sollte man die Bewertung von Locking-Algorithmen auf der Grundlage von unteilbaren
Operationen durchführen?}
\begin{answer}
Nur unteilbare Operationen sind nicht unterbrechbar.
Unteilbare Operationenen sind Maschinen-Instruktionen, also die unterste Ebene der Programm-
Ausführung. Wenn man ein Programm auf Maschinen-Code runterbricht, kann man sehr gut
erkennen, dass nach jedem Befehl eine Unterbrechung, z.B. ein Interupt zum Prozesswechsel,
erfolgen kann (z.B. durch Ablauf der Zeitscheibe). Die kritischen Abschnitte lassen sich daher
genau analysieren und Anfang und Ende festlegen.
\end{answer}

\question{66. Auf welche verschiedenen Arten kann man Verklemmungen angehen? Wie arbeitet der Bankiersalgorithmus?}
\begin{answer}
Ein Deadlock liegt an wenn z.B. zwei oder mehrere Prozesse auf Betriebsmittel warten, die nur
von anderen freigegeben werden kann, es aber nicht mehr zu der Freigabe kommen wird.
Möglickeiten:
- Deadlock ignorieren, wenn er nur selten auftreten kann, da eine Lösung unter Umständen zu
teuer ist.
- Deadlock durch Untersuchung des Betriebsmittelgraphen entdecken und Deadlock durch Zwangsentfernen
eines Prozesses beheben.
- Deadlock verhindern durch das erkennen der Randbedingung, die zum Deadlock führt:
- Exklusivität (Spooling)
- alles auf einmal anfordern (aber: Verschwendung von Ressurcen!)
- Zwangsentzug
Zyklus verhindern (Betriebsmittel nach aufsteigender Nummer anfordern und belegen), dies führt
zu einer Einschränkung der Prozesse.
- Deadlocks vermeiden: Bankiersalgorithmus.
Der Bankiersalgorithmus:
Die Idee ist, dass die maximale Anforderung von Betriebsmitteln im voraus bekannt ist. Belegung
wird nur dann gewährt, wenn das System dadurch nicht in einen Zustand gelangt, der zu einem
Deadlock führen kann. Diesem Verfahren liegt das Modell eines Bankiers zugrunde, der mit Kunden
einen Kreditrahmen aushandelt, der nach und nach eingelöst werden kann, aber die Grenzen der
leistungsfähigkeit nicht sprengt.
\end{answer}

\question{67. Wie kann man eine einseitige Synchronisation mit Hilfe von wait() und signal() vornehmen? Wie kann man diese Primitiven in etwa auf lock() und unlock() abbilden?}
\begin{answer}
TODO
\end{answer}

\question{68. Grenze die Begriffe aktives und blockierendes Warten voneinander ab.}
\begin{answer}
Beim aktiven Warten wird ständig die Schlüsselvariable eines kritischen Abschnitts überprüf, ob sieser nun frei geworden ist oder nicht. Durch das ständige Abfragen wird unter Unständen unnötig CPU-Zeit in Anspruch genommen.
Beim blockierenden Warten legt sich der betreffende Pozess schlafen, falls der kritische Abschnitt

nicht frei ist. Wird der kritische Abschnitt von dem anderen Prozess verlassen, so führt dieser ein
wakeup() aus, um die schlafenden Prozesse zu wecken.
\end{answer}

\question{69. In einer UNIX-Multiprozessorumgebung können mehrere Prozesse nebenläufig sleep() aufrufen.}
\begin{answer}
Warum ist dies ein kritischer Abschnitt? Warum kann man ihn nicht einfach davor schützen, dass
man den Aufruf von sleep() von einem Spinlock umgibt? Was wird man stattdessen tun?
Die gemeinsame Datenstruktur ist hier die Sleep-Queue. Wenn sich ein schlafender Prozess von
einm spinlock umgibt, dann kann er unter Umständen nicht wieder aufgeweckt werden, da er die
Sleep-Queue nicht freigegeben hat. Als Lösung wird eine Variante von sleep() eingeführt: sleepl().
sleepl() gibt die Sleep-Queue wieder frei, bevor die CPU abgegeben wird.
\end{answer}

\question{70. Welche zusätzlichen Eigenschaften zeichnen Semaphoren gegenüber blockierenden Locks aus?}
\begin{answer}
Es gibt zwei zusätzliche Erweiterungen bei einer Semaphore:
- Im Wartefall wird der Pozess in eine FIFO-Queue eingereiht, das heisst die Prozesse werden nach
Ankunftsreihenfolge beim kritischen Abschnitt abgearbeitet.
- Semaphore-Counting, das heisst die Semaphore enthält einen Counter, durch den die Semaphore
erst blockiert, wenn dich n Prozesse im kritischen Abschnitt befinden. Eine Semaphore wird mit
n vorinitialisiert.
\end{answer}

\question{71. Wie wird eine einseitige bzw. mehrseitige Synchronisation durch Semaphore ausgedrückt?}
\begin{answer}
- einseitige: Die Semaphore muss mit 0 vorinitialisiert werden. Wenn in einem Prozess B etwas
ausgeführt werden soll, was abhängig von einem anderen Prorzess A ist, (z.B. Ereignis), dann muss
vorher ein P() ausgeführt werden. In A muss, wenn das betreffende Ereignis stattgefunden hat, ein
V() ausgeführt werden. Wurde das V() nicht ausgeführt, und versucht B jetzt P() auszuführen,
so wird bloockiert und gewartet bis V() kommt.
- mehrseitige Synchronisation: Funktioniert wie einseitige, jedoch mit zwei Semaphoren.
\end{answer}

\question{72. Wie können Semaphore zur Lösung des Problems der speisenden Philosophen eingesetzt werden?
In welches Problem wird eine allzu einfache "Implementierung" laufen?}
\begin{answer}
Fünf Philosophen sitzen an einem Tisch mit fünf Tellern Reis. Zwischen jedem der Teller befindet
sich ein Stäbchen, also insgesamt sind auch fünf Stäbchen vorhanden. Das Problem ist, dass jeder
Philosoph zwei Stäbchen zum Essen benötigt, es können also nicht alle Philosophen gleichzeitig
essen. Nur für zwei gleichzeitig speisende Philosophen sind ausreichend Stäbchen vorhanden.
Jedes Stäbchen ist ein kritischer Abschnitt. Es kommt aber zu Verklemmungen, wenn jeder Philosoph
z.B. sein linkes Stäbchen nimmt, kann keiner der Philosophen essen.
Lösung: Einsatz von Semaphoren für Stäbchen und Philosophen.
\end{answer}

\question{73. Warum bietet eine einfache Semaphor-Implementierung mit den UNIX-eigenen sleep()/wakeup()-
Routinen keine vollständige Semaphore-Semantik?Welche zusätzlichen Massnahmen muüsste man
ergreifen?}
\begin{answer}
Bevor sich ein Prozess schlafenlegt, wäre es sinnvoll den kritischen Abschnitt wieder freizugeben,
da dieser sonst unter Umständen nicht wieder aufgeweckt werden kann. Als zusätzliche Massnahme
muss der Abschnitt also wieder freigegeben werden.
\end{answer}

\question{74. Welche Probleme gibt es mit "fairen Semaphoren"? Was sind "Konvois", was sind "donnernde Herden"?}
\begin{answer}
Duch das Einreihen der Prozesse in eine FIFO-Queue kommt es zu einer festen Reihenfolge bei
der Abarbeitung. Es kann hier zu Konvois kommen. Weiterhin kann es zu unnötig wielen Prozesswechseln
kommen, wen die Prozesse aus der FIFO-Queue entnommen werden, prüfen ob sie den
kritischen Abschnitt betreten können und wieder eingereiht werden.
Zu donnernden Herden kann es kommen, wenn man das Semaphore-Counting benutzt. Alle Prozesse,
die beim Eintreten in den kritischen Abschnitt schlafen gelegt wurden, warten praktisch
auf eine Veränderung des Counters. Wenn nun ein anderer Prozess den kritischen Abschnitt frei
gibet, indem er ein V() ausführt, werden alle wartenden Prozesse geweckt und donnern los. Es
kommt aber nur einer in den kritischen Abschnitt hinein.
\end{answer}

\question{75. Was ist ein Monitor? Unter welchen Bedingungen wird ein Monitor betreten bzw. wieder verlassen?}
\begin{answer}
Ein Monitor ist ein ADT (Abstrakter Datentyp), also mit Daten und Operationen auf diesen
Daten. Die Zugriffsoperationen sind implizit gegen nebenläufigen Zugriff geschützt. Das heisst,
der Programmierer muss sich keinen Gedanken mehr um den Schutz von kritischen Abschnitten

innerhalb des Programmes zu machen, da der Nenbenläufigkeitsschutz im Monitor bereits implementiert
ist. Vorteil dieser Lösung ist, dass eventuelles Vergessen von Schutzanweisungen nicht
mehr möglich ist.
Ein Monitor wird betreten, wenn von einer Prozedur des Programms eine entsprechende Monitorfunktion
aufgerufen wird. Verlassen wird er, wenn er warten muss (wait()) oder wenn er fertig
ist.
\end{answer}

\question{76. Aus welchen Komponenten besteht ein Petrinetz (mit Marken)?Was kann man damit beschreiben?}
\begin{answer}
Ein Petrinetz ist ein gerichteter Graph, der aus Zuständen (Stellen) und Zustandübergängen
(Transistionen) besteht. Mit Marken (Tokens) ist der aktuelle Ausführungszustand beschreibbar.
Mit einem Petrinetz kann man grafisch die Synchronisationszusammenhänge darstellen.
\end{answer}

\question{77. Wie kann man durch ein Petrinetz typische Sznchronisationsvorschriften ausdrücken?}
\begin{answer}
a) Sequenz
b) beschränkte Nebenläufigkeit
c) Unabhängigkeit?
Bei einer Sequenz a, b gibt es die Transistionen a und b, die jeweils eine Ein- und Ausgangsstelle
haben. Die Ausgangsstelle von a ist allerdings die Eingangsstelle von b.
Die beschränkte nebenläufigkeit kann man darstellen, indem man Token verwendet, um die Anzahl
der möglichen Prozesse/Threads anzuzeigen.
Bei Unabhängigkeit können zwei Prozesse beliebig oft und in beliebiger Reihenfolge gestartet
werden und somit unabhängig nebenläufig laufen.
\end{answer}

\question{78. Was kennzeichnet lebendige bzw. todesgefährdete Petrinetze?}
\begin{answer}
Bei lebendigen Petrinetzen gibt es immer Transistionen, egal welche Ausführungsreihenfolge stattgefunden
hat..
Bei todesgefährdeten Petrinetzen kann es nach einer Transistion zu einem Zustand kommen, von
dem aus keine Transistionen mehr ausgeführt werden kann.
\end{answer}

\question{79. Was wird durch einen Pfadausdruck beschrieben? Welche Operatoren werden dazu vorgesehen?
Was ist ihre Semantik?}
\begin{answer}
Mit einem Pfadausdruck kann man Angaben über mögliche Nebenläufigkeit von Zugriffsoperationen
eines ADTs machen.
Operator : : (Beschränkte) Nebenläufigkeit
Operator + : Alternative "Entweder ... oder ..."
Operator ; : Sequenz "Erst ..., dann ..."
Operator | : Unabhängikeit von Prozessen
\end{answer}

\question{80. Welche Vorteile bieten Pfadausdrücke zur Steuerung von Nebenläufigkeit im Vergleich zu Semaphoren bzw. Monitore?}
\begin{answer}
Vorteil ist die korrekte Definition dessen, was erlaubt ist oder was nicht erlaubt ist. Unterschied
\end{answer}

\question{81. Was ist der Unterschied zwischen offenen und geschlossenen Pfadausdrücken?}
\begin{answer}
Geschlossenen Pfadausdrücke: alle erlaubten Ausführungsreihenfolgen von Operationen eines synchronisierten
Datentyps (ADT mit expliziter Synchronisationsvorschrift) sind zu spezifizieren. Das
heisst alles davon abweichende ist verboten.
Offene Pfadausdrücke: alle Einschränkungen von Ausführungsreihenfolgen sind im Pfadausdruck
zu spezifizieren. Das heisst alles andere ist erlaubt.
\end{answer}

\question{82. Wie würde man das klassische Reader-/Writer-Problem als Pfadausdruck formulieren?}
\begin{answer}
Beim Reader-/Writer-Problem sollen beliebig viele Leser, aber kein Schreiber zugelassen werden,
oder ein Schreiber ohne Leser. Damit werden inkonsistente Ergebnisse verhindert.
Als Pfadausdruck: leser+writer
\end{answer}

\question{83. Was versteht man unter synchronem bzw. asynchronem Nachrichtenaustausch? Inwiefern sind
diese beiden Kommunikationsformen aufeinander abbildbar?}
\begin{answer}
Bei synchronem Datenaustausch warten Sender und Empfänger aufeinander. Das heist, send()
und recieve() wirken blockierend aufeinander. Der Empfänger muss bereit sein, die Nachricht aufzunehmen.
Bei asynchronem Datenaustausch muss der Empfänger nicht unbedingt empfangsbereit sein, damit
der Sender senden kann. Die Nachricht muss dazu aber in einem Puffer innerhalb des Kommunikationskanals
festgehalten werden. Wenn dieser Puffer zu klein ist, muss der Sender blockiert
werden, da es sonst zu einem Pufferüberlauf (Bufferover
ow) kommt.
Synchrone Kommunikation kann durch asychrone Operationen vorgenommen werden, d.h. der
Sender wartet nach dem senden auf die Bestätigung des Empfängers.
Asynchrone Kommunikation kann durch sychrone Operationen vorgenommen werden. Dazu muss
ein Pufferprozess eingeführt werden.
\end{answer}

\question{84. Wie kann man die Sychronisationseigenschaften von synchronem bzw. asynchronem Nachrichtenaustausch mit Semaphoren modellieren?}
\begin{answer}
Sema1(0);
Sema2(0);
Synchron:
A B
send(); s1.P();
s1.V(); recieve();
s2.P(); s2.V();
Asynchron:
A B
send(); s1.P();
s1.V(); recieve();
\end{answer}

\question{85. Wozu verwendet man Kanäle bzw. Ports? Was ist das?}
\begin{answer}
Kommunikation zwischen zwei Prozessen setzt die Benennung der Partner voraus. Besser wäre hier den Kanal zu benennen, über den sie kommunizieren. Die Partner bleiben dadurch "anonym".
Ports geben an, wohin gesendet werden soll. Sie werden verwendet, wenn es nur einen Sender
oder Empfänger auf einem Kanal gibt. Durch Ports ist eine dynamische Zuordnung zu Prozessen
möglich.
\end{answer}

\question{86. Was ist ein guarded command? Warum kann die Verwendung eines solchen Konzepts gerade im
Zusammenhang mit Nachrichtenaustausch interessant sein?}
\begin{answer}
Durch guarded commands ist es möglich, auf verschiedene Sender als Empfänger entsprechend
zu reagieren. Mit Hilfe von guarded commands können Unterscheidungen getroffen werden.(z.B.
if...else if....).
Wenn mehrere Wächter zutreffen, ist die Auswahl nichtdeterministisch.
\end{answer}

\question{87. Wie arbeitet der Korridor-Algorithmus zum überwachen mehrerer Eingabequellen in etwa?}
\begin{answer}
Der Korridor-Algorithmus arbeitet ähnlich wie ein Bürobote, der auf seinem Rundgang durch einen
Korridor mit vielen Büros geht. Der Bote hat einen "Warteraum", in dem er im Ruhezustand sitzt.
An jedem Büro ist eine Lampe o.ä. angebracht, die abzuarbeitende Aufträge anzeigt.
Wenn der Bote von seinem Warteraum aus sieht, das ein Auftrag abzuarbeiten ist, geht er an den
Türen aller Büros vorbei und sammelt die zu diesem Zeitpunkt anstehenden Aufträge ein. Dies
tut er in festglegter Reihenfolge. Der Bürobote sollte sich, bevor er sich wieder in den Warteraum
begibt, noch einmal umsehen, ob in der Zwischenzeit nicht neue Aufträge am Beginn seiner Runde
entstanden sind.
\end{answer}

\question{88. Worin unterscheiden sich die Eigenschaften der folgenden UNIX-Mechanismen zur Interprozesskommunikation:}
\begin{answer}
Pipes, Named Pipes, Sockets?
Wie lassen sich die Kommunikationseigenschaften von Sockets mit normaler Briefpost und Telefongespr
ächen vergleichen?
Pipe: unidirektionaler sequentieller Bytestrom von stout eines Prozesses zu stin eines anderen
Prozesses. Um eine Pipe verwenden zu können, müssen die beiden Prozesse verwand sein.
Named Pipe: (FIFO) Das Pipe-Objekt benötigt einen eindeutigen Namen (Kanal-Bezeichner). Die
beiden miteinander kommunizierenden Prozesse müssen nicht verwandt sein, auch eine Named Pipe
ist ein unidirektionaler sequentieller Bytestrom.
Sockets: es gibt zwei Arten von Sockets: Stream-Sockets und Datagramm-Sockets.
Stream-Socket: Birdirektionale Pipe, Bytestrom, sequentielle übertragung, zuverlässig und verbindungsorientiert
(Vergleich: Telefongespräch)
Datagramm-Socket: Packetübergabe, Nachrichten, beliebige Reihenfolge, u.U. unzuverlässig (Verluste
sind möglich), verbindungslos (Vergleich: Brief-/Packetzustellung)
\end{answer}

\question{89. Wie lassen sich die Kommunikationseigenschaften von Sockets in die generische Systemaufrufschnittstelle zum Zugriff auf Dateien einordnen?}
\begin{answer}
Man erzeugt sie, bekommt den Deskriptor zurück und kann auf ihnen operieren.
\end{answer}

\question{90. Warum kommt dem Adressierungsproblem in der Interkommunikation eine so grosse Bedeutung
zu? in welche zwei Teile zerfällt eine Adressangabe typischerweise?}
\begin{answer}
Ohne eindeutige Adressierung ist Kommunikation unmöglich. Nur die eindeutige und funktionierende
Adressierung ermöglicht den Austausch von Nachrichten bzw. Inhalten.
Eine Adresse zerfällt typischerweise in die Benennung des Rechners und die Benennung des Ports.
Protokolle enthalten z.B. Verabredungen zur Informationsrepräsentation, zur Fehlersicherung, zur
Flusskontrolle, zur Adressierung und zur Netzkoppelung. Dies ist üblicherweise in einer ganzen
Protokollhierachie festgelegt, TCP/IP, OSI-Schichten.
\end{answer}

\question{91. Was ist ein (Kommunikations-) Protokoll?}
\begin{answer}
Protokoll: Verabredung über die Art und Weise des Kommunikationsvorgangs.
\end{answer}

\question{92. Skizziere kurz einige typische Kommunikationsprobleme und je einen Lösungsvorschlag im Rahmen eines entsprechenden Protokolls.}
\begin{answer}
Probleme und Lösungsansätze:
- Kabel, d.h. übertragungsmedium kapput: via Routing eines anderen Weg suchen.
- Bitkipper: via Fehlererkennung, z.B. Prüfsummenberechnung eine überprüfung durchführen und
den Vorgang gegebenenfalls wiederholen.
- überlastung des Empfängers, d.h. die Nachricht kann nicht angenommen werden: via Flusskontrolle
überprüfen (Staumeldung).
- Empfänger liegt in einem anderen System, d.h. er arbeitet mit einem anderen Protokoll: die
Daten müssen entsprechen umgewandelt werden.
\end{answer}

\question{93. Skizziere einige Eigenschaften typischer Netztopologien.}
\begin{answer}
- Vollständige Vermaschung:
Ist eine aufwendige, d.h. teure Möglichkeit. Zum einen werden besonders viele Verkabelungen
benötigt, zum anderen müssen alle Adressen aller beteiligten Computer auf jedem einzelnen Netzwerkrechner
gespeichert werden.
- Ring:
Ein Ringsystem bietet den Vorteil, dass die Nachrichten einfach in eine Richtung losgeschickt
werden und die beteiligten Computer nur überprüfen ob die Nachricht für sie ist. Wenn nicht,
wird das Datenpacket weitergeleitet.
Es hat den Nachteil besonders grosser Störanfälligkeit. Wenn ein einziger Netzwerkrechner oder
ein Kabel ausfält, ist die Kommunikation "dahinterliegenden" Rechner gestört.
- Bus:
Bei einem Bussystem ist die grösste Stöanfälligkeit der Bus selbst. Fällt diese Leitung aus, sind
u.U. alle Rechner vom Netz abgeschnitten. Ausserdem muss bei dieser Netzvariante besonderes
Augenmerk auf die Reihenfolge der Nachrichtenübetragung gelegt werden.
- Stern:
Bei einem Stern geschieht die Speicherung der Adressen für die Weiterleitung nur auf dem Zentralrechner.
Besonderer Nachteil eines Sterns ist die Möglichkeit, dass der zentrale Rechner ausfällt, in
diesem Fall ist keinerlei Kommunikation mehr möglich. Allerdings stört der Ausfall eines einzelnen
Computers oder einer übertragungsleitung die Funktionsfähigkeit des restlichen Netzes in keiner
Weise.
- allgemeines Netz:
Ein allgemeines Netz ist durch die Möglichkeit bei Störungen andere Wege zu suchen, in seiner
Funktionsfähigkeit eine sehr Fehler tolerante Netzwerkvariante.
\end{answer}

\question{94. Welche besondere Bedeutung kommt dem Protokoll IP zu?}
\begin{answer}
Das Internet Protokoll sorgt für die Integration von Anwendungen und Medien. Es ermöglicht
eine Netzübergreifende Adressierung und ist Packet-orientiert.
Durch die mit IP bestehenden Möglichkeiten ist es zum wichtigsten und am weitesten verbreiteten
Protokoll geworden.
\end{answer}

\question{95. Was ist ein Remote Procedure Call (RPC), und welche Parameter wird man typischerweise dabei übergeben? Was haben RPCs mit dem Client/Server-Modell zu tun?}
\begin{answer}
TODO
\end{answer}

\question{96. Nenne einige absichtliche und unabsichtliche Angriffe auf Hardware, Software und/oder Daten.}
\begin{answer}
Wie können solche Angriffe klassifiziert werden?
absichtliche Angiffe:
- Hardware:
Zerstörung, herbeiführen von Störungen, Diebstahl
- Software:
Zerstörung, Fälschung, Kopie, Viren, Würmer
unabsichtliche Angiffe:
- Hardware:
Speisen, Getränke, Wasserschäden, Mäuse
- Software:
Bugs, Bedienfehler
Klassifizierung:
- Abfangen: Anzapfen, Manipulation
- Modifikation: Daten verfälschen, Programme verändern
- Unterbrechung: Zerstörung, Löschen von Daten

\end{answer}

\question{97. Welche grundsätzlichen Sicherheitsziele kann man unterscheiden? Was ist eine Sicherheitspolitik?}
\begin{answer}
Eine Sicherheitspolitik soll das reibungslose Erfüllen der vom System zu erledigenden Aufgaben
sicherstellen. Dabei befinden sich die einzelnen Faktoren in einem Spannungsfeld, hohe Kosten
stehen z.B. immer wieder einer besonders hohen Sicherheit gegenüber. Entsprechend muss im
Einzelfall die Wahrscheinlichkeit einer Betriebsstörung und ihre möglichen Folgen gegen den Sicherheitsaufwand
abgewogen werden.
Als grundsätzliche Sicherheitsziele können Gemeinhaltung, Unversehrtheit und Verfügbarkeit unterschieden
werden.
\end{answer}

\question{98. Auf welche verschiedenen Arten kann sich ein Benutzer authentifizieren?}
\begin{answer}
Wissen: z.B. Passwort
Besitz: z. B. Schlüssel, Chipkarte
Persönliche Merkmale: z.B. Fingerabdruck, Iris, Sprache
\end{answer}

\question{99. Welche Komponenten enthält eine Zugriffskontrollmatrix? Wie ordnen sich die Dateizugriffsrechte in UNIX in dieses Schema ein?}
\begin{answer}
Eine dreidimensionale Zugriffskontrollmatrix enthält für jeden User, jede Datei Lese- und Schreibrechte.
Die drei Dimensionen sind also User-Identety, Rechte und Datei.
Die Dateizugriffsrechte in UNIX ordnen dem Besitzer einer Datei, der zugehörigen Gruppe und
dem "Rest der Welt" Lese-, Schreib- und Ausführungsrechte zu.
\end{answer}

\question{100. Charakterisiere symetrische und asymetrische Verschlüsselungsverfahren. Wie können sie zur Realiesierung einer Vertraulichkeit eingesetzt werden? Warum werden häufig Mischformen eingesetzt?}
\begin{answer}
Bei symetrischer Verschlüsselung existieren zwei gleiche Schlüssel. Das hat den Nachteil, das bei bekannt werden des Schlüssels die Vertraulichkeit nicht mehr gegeben ist.
Bei asymetrischer Verschlüsselung existieren insgesamt vier Schlüssel: zwei private und zwei öffentliche Schlüssel. Die öffentlichen Schlüssel können allgemein bekannt sein. Die Verschlüsselung selbst passiert mit dem privaten Schlüssel des Senders und dem öffentlichen Schlüssel des Empfängers.
Die Entschlüsselung einer Nachricht erfolgt mit dem privaten Schlüssel des Empfängers und dem
öffentlichen Schlüssel des Senders.

Asymetrische Verschlüsselung ist erheblicher rechenintensiver als Symetrische. Allerdings ist die
symetrische Verschlüsselung unsicherer als die Asymetrische. Deshalb werden oft Mischformen
eingesetzt, z.B. werden die symetrischen Schlüssel mit Hilfe asymetrischer Verschlüsselung ausgetauscht
um die Schlüsselübergabe so sicher als möglich zu machen, die Kommunikation selbst
findet dann aber mit Hilfe der symetrischen Verschl üsselung statt um eine angemessene Geschwindigkeit
(z.B. Videokonferenzen) zu gewährleisten.
\end{answer}

\end{document}
